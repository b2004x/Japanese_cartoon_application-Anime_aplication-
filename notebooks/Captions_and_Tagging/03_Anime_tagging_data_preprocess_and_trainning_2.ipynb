{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61452,"sourceType":"datasetVersion","datasetId":38986},{"sourceId":266085082,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport json\nimport shutil\n\ncaption_dir = '/kaggle/input/tagged-anime-illustrations/danbooru-metadata/danbooru-metadata'\n\nid_to_tags = {}\n\nfor filename in os.listdir(caption_dir):\n    f_path = os.path.join(caption_dir, filename)\n    if os.path.isfile(f_path):\n        with open(f_path, 'r') as f:\n            for line in f:\n                data = json.loads(line.rstrip())\n                tags = [x[\"name\"] for x in data[\"tags\"]]\n                caption = \" \".join(tags)\n                id_to_tags[data[\"id\"]] = caption ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:40:40.950564Z","iopub.execute_input":"2025-10-07T10:40:40.950812Z","iopub.status.idle":"2025-10-07T10:42:56.999505Z","shell.execute_reply.started":"2025-10-07T10:40:40.950792Z","shell.execute_reply":"2025-10-07T10:42:56.998903Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from collections import Counter\n\ntag_counter = Counter()\nfor tags in id_to_tags.values():\n    for tag in tags.split(\" \"):\n        tag = tag.strip()\n        if tag:  # avoid empty strings\n            tag_counter[tag] += 1\n            \ntop_tags = [tag for tag, _ in tag_counter.most_common(2000)]\n\ntop_tags_set = set(top_tags)\n\ntop_2000_id_to_tags = {\n    img_id: \" \".join([t for t in tags.split(\" \") if t in top_tags_set])\n    for img_id, tags in id_to_tags.items()\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:42:57.000609Z","iopub.execute_input":"2025-10-07T10:42:57.000990Z","iopub.status.idle":"2025-10-07T10:43:41.012283Z","shell.execute_reply.started":"2025-10-07T10:42:57.000952Z","shell.execute_reply":"2025-10-07T10:43:41.011526Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from collections import Counter\n\nfiltered_tag_counter_2000 = Counter()\n\nfor tags in top_2000_id_to_tags.values():\n    for tag in tags.split(\" \"):\n        tag = tag.strip()\n        if tag:  \n            filtered_tag_counter_2000[tag] += 1\n\nprint(\"Total unique tags:\", len(filtered_tag_counter_2000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:43:41.013125Z","iopub.execute_input":"2025-10-07T10:43:41.013374Z","iopub.status.idle":"2025-10-07T10:44:05.388427Z","shell.execute_reply.started":"2025-10-07T10:43:41.013350Z","shell.execute_reply":"2025-10-07T10:44:05.387807Z"}},"outputs":[{"name":"stdout","text":"Total unique tags: 2000\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(top_2000_id_to_tags[\"1017000\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:44:05.389772Z","iopub.execute_input":"2025-10-07T10:44:05.389953Z","iopub.status.idle":"2025-10-07T10:44:05.393681Z","shell.execute_reply.started":"2025-10-07T10:44:05.389939Z","shell.execute_reply":"2025-10-07T10:44:05.393151Z"}},"outputs":[{"name":"stdout","text":"1girl bow brown_hair detached_sleeves frilled_skirt frills hair_bow hair_ribbon hair_tubes hakurei_reimu highres midriff navel ofuda red_eyes red_skirt ribbon sarashi skirt skirt_set solo standing touhou yin_yang\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"unique_tags = list(filtered_tag_counter_2000.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:44:05.394351Z","iopub.execute_input":"2025-10-07T10:44:05.394688Z","iopub.status.idle":"2025-10-07T10:44:05.408352Z","shell.execute_reply.started":"2025-10-07T10:44:05.394664Z","shell.execute_reply":"2025-10-07T10:44:05.407863Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass DanbooruMultiLabelDataset(Dataset):\n    def __init__(self, root_dir, label_dict, unique_tags, transform=None):\n        \"\"\"\n        root_dir: folder with all subfolders of images\n        label_dict: dict mapping 'image_id' -> list of tags\n        unique_tags: list of all unique tags (defines the multi-label space)\n        \"\"\"\n        self.root_dir = root_dir\n        self.label_dict = label_dict\n        self.tag_to_idx = {tag: i for i, tag in enumerate(unique_tags)}\n        self.transform = transform\n\n        # Collect image paths\n        self.image_paths = []\n        for subdir, _, files in os.walk(root_dir):\n            for f in files:\n                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n                    img_id = os.path.splitext(f)[0]\n                    if img_id in label_dict:\n                        self.image_paths.append(os.path.join(subdir, f))\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def encode_tags(self, tags):\n        vec = torch.zeros(len(self.tag_to_idx), dtype=torch.float32)\n        for tag in tags:\n            if tag in self.tag_to_idx:\n                vec[self.tag_to_idx[tag]] = 1.0\n        return vec\n\n    def __getitem__(self, idx):\n        path = self.image_paths[idx]\n        img = Image.open(path).convert(\"RGB\")\n\n        img_id = os.path.splitext(os.path.basename(path))[0]\n        tags = self.label_dict[img_id]\n        label_vec = self.encode_tags(tags)\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label_vec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:44:05.409167Z","iopub.execute_input":"2025-10-07T10:44:05.409411Z","iopub.status.idle":"2025-10-07T10:44:16.636826Z","shell.execute_reply.started":"2025-10-07T10:44:05.409370Z","shell.execute_reply":"2025-10-07T10:44:16.635991Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\ndataset = DanbooruMultiLabelDataset(\n    root_dir=\"/kaggle/input/tagged-anime-illustrations/danbooru-images/danbooru-images\",\n    label_dict=top_2000_id_to_tags,\n    unique_tags=unique_tags,\n    transform=transform\n)\n\ndataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)\n\nfor images, label_vecs in dataloader:\n    print(images.shape)      # (B, 3, 224, 224)\n    print(label_vecs.shape)  # (B, num_tags)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:44:16.637529Z","iopub.execute_input":"2025-10-07T10:44:16.637831Z","iopub.status.idle":"2025-10-07T10:53:45.247114Z","shell.execute_reply.started":"2025-10-07T10:44:16.637813Z","shell.execute_reply":"2025-10-07T10:53:45.246402Z"}},"outputs":[{"name":"stdout","text":"torch.Size([16, 3, 224, 224])\ntorch.Size([16, 2000])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from torch.utils.data import Subset\nfrom sklearn.model_selection import train_test_split\n\nRANDOM_SEED = 42\n\nn = len(dataset)\nhalf = n // 2\n\n# ✅ Split into ordered halves first\nfirst_half_idx = list(range(0, half))\nsecond_half_idx = list(range(half, n))\n\nfirst_half = Subset(dataset, first_half_idx)\nsecond_half = Subset(dataset, second_half_idx)\n\nprint(f\"First half: {len(first_half)} samples\")\nprint(f\"Second half: {len(second_half)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:53:45.248351Z","iopub.execute_input":"2025-10-07T10:53:45.248672Z","iopub.status.idle":"2025-10-07T10:53:45.914371Z","shell.execute_reply.started":"2025-10-07T10:53:45.248638Z","shell.execute_reply":"2025-10-07T10:53:45.913514Z"}},"outputs":[{"name":"stdout","text":"First half: 168516 samples\nSecond half: 168517 samples\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def split_80_10_10(subset, seed):\n    n = len(subset)\n    indices = list(range(n))\n    train_idx, temp_idx = train_test_split(\n        indices, test_size=0.2, random_state=seed, shuffle=True\n    )\n    val_idx, test_idx = train_test_split(\n        temp_idx, test_size=0.5, random_state=seed, shuffle=True\n    )\n    return (\n        Subset(subset, train_idx),\n        Subset(subset, val_idx),\n        Subset(subset, test_idx),\n    )\n\nfirst_train, first_val, first_test = split_80_10_10(first_half, seed=RANDOM_SEED)\nsecond_train, second_val, second_test = split_80_10_10(second_half, seed=RANDOM_SEED + 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:53:45.915327Z","iopub.execute_input":"2025-10-07T10:53:45.915774Z","iopub.status.idle":"2025-10-07T10:53:46.003336Z","shell.execute_reply.started":"2025-10-07T10:53:45.915745Z","shell.execute_reply":"2025-10-07T10:53:46.002510Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def make_loader(subset, batch_size=64, shuffle=True):\n    return DataLoader(\n        subset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        num_workers=4,\n        pin_memory=True,\n        persistent_workers=True\n    )\n\ntrain_loader_1 = make_loader(first_train)\nval_loader_1   = make_loader(first_val, shuffle=False)\ntest_loader_1  = make_loader(first_test, shuffle=False)\n\ntrain_loader_2 = make_loader(second_train)\nval_loader_2   = make_loader(second_val, shuffle=False)\ntest_loader_2  = make_loader(second_test, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:53:46.005964Z","iopub.execute_input":"2025-10-07T10:53:46.006237Z","iopub.status.idle":"2025-10-07T10:53:46.011768Z","shell.execute_reply.started":"2025-10-07T10:53:46.006206Z","shell.execute_reply":"2025-10-07T10:53:46.011204Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\n# Load the model\nmodel = torch.hub.load('RF5/danbooru-pretrained', 'resnet50')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:53:46.012366Z","iopub.execute_input":"2025-10-07T10:53:46.012630Z","iopub.status.idle":"2025-10-07T10:53:48.895397Z","shell.execute_reply.started":"2025-10-07T10:53:46.012613Z","shell.execute_reply":"2025-10-07T10:53:48.894756Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n  warnings.warn(\nDownloading: \"https://github.com/RF5/danbooru-pretrained/zipball/master\" to /root/.cache/torch/hub/master.zip\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\nDownloading: \"https://github.com/RF5/danbooru-pretrained/releases/download/v0.1/resnet50-13306192.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-13306192.pth\n100%|██████████| 110M/110M [00:00<00:00, 175MB/s]  \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:53:48.896244Z","iopub.execute_input":"2025-10-07T10:53:48.896501Z","iopub.status.idle":"2025-10-07T10:53:48.902072Z","shell.execute_reply.started":"2025-10-07T10:53:48.896483Z","shell.execute_reply":"2025-10-07T10:53:48.901413Z"}},"outputs":[{"name":"stdout","text":"Sequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (5): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (6): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (7): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): Flatten()\n    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=4096, out_features=512, bias=True)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=6000, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch.nn as nn\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_tags = len(unique_tags)\n# Replace final layer\nmodel[1][8] = nn.Linear(in_features=512, out_features=num_tags)\nprint(f\"✅ Replaced final layer with Linear(512, {num_tags})\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:53:48.902886Z","iopub.execute_input":"2025-10-07T10:53:48.903147Z","iopub.status.idle":"2025-10-07T10:53:48.966314Z","shell.execute_reply.started":"2025-10-07T10:53:48.903122Z","shell.execute_reply":"2025-10-07T10:53:48.965795Z"}},"outputs":[{"name":"stdout","text":"✅ Replaced final layer with Linear(512, 2000)\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (5): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (6): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (7): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): Flatten()\n    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=4096, out_features=512, bias=True)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2000, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Load previous fine-tuned weights\ncheckpoint_path = \"/kaggle/input/anime-tagging-data-preprocess-and-trainning/model_half1_finetuned.pth\"\nmodel.load_state_dict(torch.load(checkpoint_path, map_location=device))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:53:48.966938Z","iopub.execute_input":"2025-10-07T10:53:48.967166Z","iopub.status.idle":"2025-10-07T10:53:49.995790Z","shell.execute_reply.started":"2025-10-07T10:53:48.967141Z","shell.execute_reply":"2025-10-07T10:53:49.995190Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Freeze feature extractor\nfor param in model[0].parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:53:49.996578Z","iopub.execute_input":"2025-10-07T10:53:49.996808Z","iopub.status.idle":"2025-10-07T10:53:50.000853Z","shell.execute_reply.started":"2025-10-07T10:53:49.996790Z","shell.execute_reply":"2025-10-07T10:53:50.000042Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\ncriterion = nn.BCEWithLogitsLoss()  # multi-label classification\noptimizer = optim.Adam(model[1].parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:53:50.001696Z","iopub.execute_input":"2025-10-07T10:53:50.001946Z","iopub.status.idle":"2025-10-07T10:53:50.015989Z","shell.execute_reply.started":"2025-10-07T10:53:50.001929Z","shell.execute_reply":"2025-10-07T10:53:50.015507Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n\n\nnum_epochs_head = 5\nfor epoch in range(num_epochs_head):\n    model.train()\n    train_loss = 0.0\n\n    for imgs, labels in tqdm(train_loader_2, desc=f\"Epoch {epoch+1}/{num_epochs_head} [Head]\"):\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels.float())\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * imgs.size(0)\n\n    train_loss /= len(train_loader_2.dataset)\n\n    # Validation\n    model.eval()\n    all_preds, all_labels = [], []\n    val_loss = 0.0\n    with torch.no_grad():\n        for imgs, labels in val_loader_2:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels.float())\n            val_loss += loss.item() * imgs.size(0)\n\n            preds = (torch.sigmoid(outputs) > 0.5).int().cpu()\n            all_preds.append(preds)\n            all_labels.append(labels.cpu())\n\n    all_preds = torch.cat(all_preds)\n    all_labels = torch.cat(all_labels)\n    f1 = f1_score(all_labels, all_preds, average=\"micro\")\n    precision = precision_score(all_labels, all_preds, average=\"micro\")\n    recall = recall_score(all_labels, all_preds, average=\"micro\")\n    val_loss /= len(val_loader_2.dataset)\n\n    # print(f\"Epoch [{epoch+1}/{num_epochs_head}] - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | F1: {f1:.4f}\"|)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs_head}] - Train Loss: {train_loss:.4f} | \"\n          f\"Val Loss: {val_loss:.4f} | F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n\n# #Unfreeze backbone for fine-tuning\n\nfor param in model[0].parameters():\n    param.requires_grad = True\n\noptimizer = optim.Adam(model.parameters(), lr=1e-5)\nnum_epochs_finetune = 3\n\n\npatience = 1  \nbest_f1 = 0.0\npatience_counter = 0 \nfor epoch in range(num_epochs_finetune):\n    model.train()\n    train_loss = 0.0\n\n    for imgs, labels in tqdm(train_loader_2, desc=f\"Epoch {epoch+1}/{num_epochs_finetune} [Fine-tune]\"):\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels.float())\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * imgs.size(0)\n\n    train_loss /= len(train_loader_2.dataset)\n    \n    # Validation\n    model.eval()\n    all_preds, all_labels = [], []\n    val_loss = 0.0\n    with torch.no_grad():\n        for imgs, labels in val_loader_2:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels.float())\n            val_loss += loss.item() * imgs.size(0)\n\n            preds = (torch.sigmoid(outputs) > 0.5).int().cpu()\n            all_preds.append(preds)\n            all_labels.append(labels.cpu())\n\n    all_preds = torch.cat(all_preds)\n    all_labels = torch.cat(all_labels)\n    f1 = f1_score(all_labels, all_preds, average=\"micro\")\n    precision = precision_score(all_labels, all_preds, average=\"micro\")\n    recall = recall_score(all_labels, all_preds, average=\"micro\")\n    val_loss /= len(val_loader_2.dataset)\n\n    # print(f\"Epoch [{epoch+1}/{num_epochs_head}] - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | F1: {f1:.4f}\"|)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs_finetune}] - Train Loss: {train_loss:.4f} | \"\n          f\"Val Loss: {val_loss:.4f} | F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n    \n        \n    if f1 > best_f1:\n        best_f1 = f1\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        print(f\" No improvement in F1. Patience: {patience_counter}/{patience}\")\n        if patience_counter >= patience:\n            print(\"Early stopping triggered.\")\n            break\n            \n\nmodel.eval()\nall_preds, all_labels = [], []\n\nwith torch.no_grad():\n    for imgs, labels in tqdm(test_loader_2, desc=\"Testing\"):\n        imgs, labels = imgs.to(device), labels.to(device)\n        outputs = model(imgs)\n        preds = (torch.sigmoid(outputs) > 0.5).int().cpu()\n        all_preds.append(preds)\n        all_labels.append(labels.cpu())\n\nall_preds = torch.cat(all_preds)\nall_labels = torch.cat(all_labels)\n\n\nprecision = precision_score(all_labels, all_preds, average=\"micro\")\nrecall = recall_score(all_labels, all_preds, average=\"micro\")\nf1 = f1_score(all_labels, all_preds, average=\"micro\")\nprint(f\"✅ Test F1 Score after second half: {f1:.4f}\")\nprint(f\"Precision: {precision:.4f}, Recall: {recall:.4f}\")\n\n\n\ntorch.save(model.state_dict(), \"model_half2_finetuned.pth\")\nprint(\"✅ Model saved after second half training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T10:53:50.016820Z","iopub.execute_input":"2025-10-07T10:53:50.017074Z","iopub.status.idle":"2025-10-07T12:32:34.097751Z","shell.execute_reply.started":"2025-10-07T10:53:50.017048Z","shell.execute_reply":"2025-10-07T12:32:34.096625Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/5 [Head]:  90%|████████▉ | 1894/2107 [08:46<00:53,  4.00it/s]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:760: UserWarning: Metadata Warning, tag 296 had too many entries: 2, expected 1\n  warnings.warn(\nEpoch 1/5 [Head]: 100%|██████████| 2107/2107 [09:45<00:00,  3.60it/s]\n/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:760: UserWarning: Metadata Warning, tag 296 had too many entries: 2, expected 1\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/5] - Train Loss: 0.0003 | Val Loss: 0.0019 | F1: 0.6163 | Precision: 0.4705 | Recall: 0.8929\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5 [Head]:   6%|▋         | 132/2107 [00:30<07:45,  4.24it/s]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:760: UserWarning: Metadata Warning, tag 296 had too many entries: 2, expected 1\n  warnings.warn(\nEpoch 2/5 [Head]: 100%|██████████| 2107/2107 [07:44<00:00,  4.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/5] - Train Loss: 0.0003 | Val Loss: 0.0024 | F1: 0.6163 | Precision: 0.4834 | Recall: 0.8499\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5 [Head]: 100%|██████████| 2107/2107 [07:46<00:00,  4.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/5] - Train Loss: 0.0003 | Val Loss: 0.0021 | F1: 0.6714 | Precision: 0.5524 | Recall: 0.8556\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5 [Head]:  13%|█▎        | 268/2107 [01:00<06:37,  4.62it/s]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:760: UserWarning: Metadata Warning, tag 296 had too many entries: 2, expected 1\n  warnings.warn(\nEpoch 4/5 [Head]: 100%|██████████| 2107/2107 [07:45<00:00,  4.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/5] - Train Loss: 0.0003 | Val Loss: 0.0003 | F1: 0.8035 | Precision: 0.7167 | Recall: 0.9141\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5 [Head]: 100%|██████████| 2107/2107 [07:44<00:00,  4.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/5] - Train Loss: 0.0003 | Val Loss: 0.0004 | F1: 0.7802 | Precision: 0.7073 | Recall: 0.8697\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3 [Fine-tune]:  61%|██████    | 1287/2107 [14:23<09:09,  1.49it/s]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:760: UserWarning: Metadata Warning, tag 296 had too many entries: 2, expected 1\n  warnings.warn(\nEpoch 1/3 [Fine-tune]: 100%|██████████| 2107/2107 [23:32<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/3] - Train Loss: 0.0003 | Val Loss: 0.0003 | F1: 0.8030 | Precision: 0.7425 | Recall: 0.8741\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3 [Fine-tune]: 100%|██████████| 2107/2107 [23:35<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/3] - Train Loss: 0.0003 | Val Loss: 0.0003 | F1: 0.7958 | Precision: 0.7437 | Recall: 0.8556\n No improvement in F1. Patience: 1/1\nEarly stopping triggered.\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|██████████| 264/264 [01:15<00:00,  3.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ Test F1 Score after second half: 0.7959\nPrecision: 0.7445, Recall: 0.8549\n✅ Model saved after second half training\n","output_type":"stream"}],"execution_count":17}]}