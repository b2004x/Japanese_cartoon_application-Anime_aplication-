{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca8e794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T04:44:50.160667Z",
     "iopub.status.busy": "2025-09-20T04:44:50.160441Z",
     "iopub.status.idle": "2025-09-20T16:00:36.818931Z",
     "shell.execute_reply": "2025-09-20T16:00:36.818065Z"
    },
    "papermill": {
     "duration": 40546.675942,
     "end_time": "2025-09-20T16:00:36.833682",
     "exception": false,
     "start_time": "2025-09-20T04:44:50.157740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 04:45:09.421978: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758343509.799780      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758343509.911205      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00000-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00001-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00002-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00003-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00004-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00005-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00006-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00007-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00008-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00009-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00010-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00011-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00012-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00013-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00014-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00015-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00016-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00017-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00018-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00019-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00020-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00021-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00022-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00023-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00024-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00025-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00026-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00027-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00028-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00029-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00030-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00031-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00032-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00033-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00034-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00035-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00036-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00037-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00038-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00039-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00040-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00041-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00042-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00043-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00044-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00045-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00046-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00047-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00048-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00049-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00050-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00051-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00052-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00053-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00054-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00055-of-00057.arrow\n",
      "✅ Loaded /kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296/anime-captions-train-00056-of-00057.arrow\n",
      "✅ Full dataset size: 337038\n",
      "✅ Half2 size: 168519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['text_decoder.cls.predictions.decoder.bias'].\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80000' max='80000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80000/80000 11:14:14, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.475800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.497300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.506400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.478100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.475700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.485200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>0.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.483400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>0.477100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.468300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>0.471200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.469700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.473400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>0.472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.462100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>0.465500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>0.462300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.456800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>0.454600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.455200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>0.455300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>0.446600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.449800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>0.446300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.442600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>0.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.432600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>0.441000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.442600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>0.437600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>0.422800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.430300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>0.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.418800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>0.425700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.419300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63500</td>\n",
       "      <td>0.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64500</td>\n",
       "      <td>0.282700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65500</td>\n",
       "      <td>0.283100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.286200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66500</td>\n",
       "      <td>0.278200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.284300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>0.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.281800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68500</td>\n",
       "      <td>0.275100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.278300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69500</td>\n",
       "      <td>0.271400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70500</td>\n",
       "      <td>0.272500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71500</td>\n",
       "      <td>0.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.260300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>0.268800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.266600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73500</td>\n",
       "      <td>0.266200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.262700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74500</td>\n",
       "      <td>0.262800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75500</td>\n",
       "      <td>0.261300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.260100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76500</td>\n",
       "      <td>0.259700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>0.256800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>0.249300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.253500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78500</td>\n",
       "      <td>0.250900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>0.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79500</td>\n",
       "      <td>0.250200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.250100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Continued training complete! Final model saved at ./blip-anime-half2-final\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Continue Fine-tuning BLIP-base (Second Half)\n",
    "# Kaggle (Full dataset, last 50%)\n",
    "# ============================================\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/kaggle/working/hf_cache\"\n",
    "os.makedirs(\"/kaggle/working/hf_cache\", exist_ok=True)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Check GPU\n",
    "# --------------------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Load BLIP with checkpoint\n",
    "# --------------------------------------------\n",
    "processor = BlipProcessor.from_pretrained(\"/kaggle/input/caption-1/blip-anime-half1-final\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\n",
    "    \"/kaggle/input/caption-1/blip-anime/checkpoint-40000\"\n",
    ").to(device)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Training arguments\n",
    "# (only +45k more steps, total = 85k)\n",
    "# --------------------------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./blip-anime\",\n",
    "    per_device_train_batch_size=4,\n",
    "    fp16=True,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10000,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=500,\n",
    "    max_steps=80000,   # 40k already done, +45k = 85k total\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Preprocessing function\n",
    "# --------------------------------------------\n",
    "def preprocess(example):\n",
    "    try:\n",
    "        image = example[\"image\"]\n",
    "        if isinstance(image, str):\n",
    "            image = Image.open(image).convert(\"RGB\")\n",
    "        else:\n",
    "            image = image.convert(\"RGB\")\n",
    "\n",
    "        inputs = processor(images=image, text=example[\"text\"], return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"][0],\n",
    "            \"attention_mask\": inputs[\"attention_mask\"][0],\n",
    "            \"pixel_values\": inputs[\"pixel_values\"][0],\n",
    "        }\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# --------------------------------------------\n",
    "# Collator (pads captions dynamically)\n",
    "# --------------------------------------------\n",
    "# def collate_fn(batch):\n",
    "#     batch = [x for x in batch if x]  # drop empties\n",
    "\n",
    "#     input_ids = [x[\"input_ids\"] for x in batch]\n",
    "#     attention_masks = [x[\"attention_mask\"] for x in batch]\n",
    "#     pixel_values = torch.stack([x[\"pixel_values\"] for x in batch])\n",
    "\n",
    "#     input_ids = pad_sequence(input_ids, batch_first=True, padding_value=processor.tokenizer.pad_token_id)\n",
    "#     attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
    "\n",
    "#     return {\n",
    "#         \"input_ids\": input_ids,\n",
    "#         \"attention_mask\": attention_masks,\n",
    "#         \"pixel_values\": pixel_values,\n",
    "#         \"labels\": input_ids.clone(),\n",
    "#     }\n",
    "def collate_fn(batch):\n",
    "    new_batch = []\n",
    "    for example in batch:\n",
    "        try:\n",
    "            image = example[\"image\"]\n",
    "            if isinstance(image, str):\n",
    "                image = Image.open(image).convert(\"RGB\")\n",
    "            else:\n",
    "                image = image.convert(\"RGB\")\n",
    "\n",
    "            inputs = processor(images=image, text=example[\"text\"], return_tensors=\"pt\")\n",
    "\n",
    "            new_batch.append({\n",
    "                \"input_ids\": inputs[\"input_ids\"][0],\n",
    "                \"attention_mask\": inputs[\"attention_mask\"][0],\n",
    "                \"pixel_values\": inputs[\"pixel_values\"][0],\n",
    "            })\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    input_ids = [x[\"input_ids\"] for x in new_batch]\n",
    "    attention_masks = [x[\"attention_mask\"] for x in new_batch]\n",
    "    pixel_values = torch.stack([x[\"pixel_values\"] for x in new_batch])\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=processor.tokenizer.pad_token_id)\n",
    "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_masks,\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"labels\": input_ids.clone(),\n",
    "    }\n",
    "\n",
    "# --------------------------------------------\n",
    "# Dataset (load directly from Kaggle input, no copy)\n",
    "# --------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "src_dir = \"/kaggle/input/d/nguyengiabach1810/caption-1/none-yet___anime-captions/default/0.0.0/2f1272a94691fd3c8dede0a3697057ab1d4d2296\"\n",
    "files = sorted(glob.glob(f\"{src_dir}/anime-captions-train-*-of-00057.arrow\"))\n",
    "\n",
    "valid_datasets = []\n",
    "for f in files:\n",
    "    try:\n",
    "        ds = Dataset.from_file(f)\n",
    "        valid_datasets.append(ds)\n",
    "        print(f\"✅ Loaded {f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Skipping corrupted shard {f}: {e}\")\n",
    "\n",
    "dataset = concatenate_datasets(valid_datasets)\n",
    "print(\"✅ Full dataset size:\", len(dataset))\n",
    "\n",
    "# Take last 50%\n",
    "half = len(dataset) // 2\n",
    "half2 = dataset.select(range(half, len(dataset)))\n",
    "print(\"✅ Half2 size:\", len(half2))\n",
    "\n",
    "# Preprocess (cache in writable dir)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Setup Trainer\n",
    "# --------------------------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=half2,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Continue training from checkpoint\n",
    "# --------------------------------------------\n",
    "trainer.train(resume_from_checkpoint=\"/kaggle/input/caption-1/blip-anime/checkpoint-40000\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Save final model\n",
    "# --------------------------------------------\n",
    "model.save_pretrained(\"./blip-anime-half2-final\")\n",
    "processor.save_pretrained(\"./blip-anime-half2-final\")\n",
    "\n",
    "print(\"\\n✅ Continued training complete! Final model saved at ./blip-anime-half2-final\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8293807,
     "sourceId": 13093999,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8304302,
     "sourceId": 13109539,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 262322035,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40555.262517,
   "end_time": "2025-09-20T16:00:39.839192",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-20T04:44:44.576675",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
