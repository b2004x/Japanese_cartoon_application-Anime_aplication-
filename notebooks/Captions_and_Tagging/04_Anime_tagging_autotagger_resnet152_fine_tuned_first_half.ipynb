{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2f76b5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-21T16:49:54.205644Z",
     "iopub.status.busy": "2025-10-21T16:49:54.205361Z",
     "iopub.status.idle": "2025-10-21T16:51:55.604657Z",
     "shell.execute_reply": "2025-10-21T16:51:55.603937Z"
    },
    "papermill": {
     "duration": 121.405309,
     "end_time": "2025-10-21T16:51:55.606377",
     "exception": false,
     "start_time": "2025-10-21T16:49:54.201068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "caption_dir = '/kaggle/input/tagged-anime-illustrations/danbooru-metadata/danbooru-metadata'\n",
    "\n",
    "id_to_tags = {}\n",
    "\n",
    "for filename in os.listdir(caption_dir):\n",
    "    f_path = os.path.join(caption_dir, filename)\n",
    "    if os.path.isfile(f_path):\n",
    "        with open(f_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line.rstrip())\n",
    "                tags = [x[\"name\"] for x in data[\"tags\"]]\n",
    "                caption = \" \".join(tags)\n",
    "                id_to_tags[data[\"id\"]] = caption "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec549a67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T16:51:55.613735Z",
     "iopub.status.busy": "2025-10-21T16:51:55.613369Z",
     "iopub.status.idle": "2025-10-21T16:52:43.747976Z",
     "shell.execute_reply": "2025-10-21T16:52:43.747023Z"
    },
    "papermill": {
     "duration": 48.139648,
     "end_time": "2025-10-21T16:52:43.749589",
     "exception": false,
     "start_time": "2025-10-21T16:51:55.609941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tag_counter = Counter()\n",
    "for tags in id_to_tags.values():\n",
    "    for tag in tags.split(\" \"):\n",
    "        tag = tag.strip()\n",
    "        if tag:  # avoid empty strings\n",
    "            tag_counter[tag] += 1\n",
    "            \n",
    "top_tags = [tag for tag, _ in tag_counter.most_common(500)]\n",
    "\n",
    "top_tags_set = set(top_tags)\n",
    "\n",
    "top_2000_id_to_tags = {\n",
    "    img_id: \" \".join([t for t in tags.split(\" \") if t in top_tags_set])\n",
    "    for img_id, tags in id_to_tags.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41705695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T16:52:43.756459Z",
     "iopub.status.busy": "2025-10-21T16:52:43.756226Z",
     "iopub.status.idle": "2025-10-21T16:53:04.979416Z",
     "shell.execute_reply": "2025-10-21T16:53:04.978500Z"
    },
    "papermill": {
     "duration": 21.228041,
     "end_time": "2025-10-21T16:53:04.980902",
     "exception": false,
     "start_time": "2025-10-21T16:52:43.752861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tags: 500\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "filtered_tag_counter_2000 = Counter()\n",
    "\n",
    "for tags in top_2000_id_to_tags.values():\n",
    "    for tag in tags.split(\" \"):\n",
    "        tag = tag.strip()\n",
    "        if tag:  \n",
    "            filtered_tag_counter_2000[tag] += 1\n",
    "\n",
    "print(\"Total unique tags:\", len(filtered_tag_counter_2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45392794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T16:53:04.987242Z",
     "iopub.status.busy": "2025-10-21T16:53:04.987022Z",
     "iopub.status.idle": "2025-10-21T16:53:04.990991Z",
     "shell.execute_reply": "2025-10-21T16:53:04.990331Z"
    },
    "papermill": {
     "duration": 0.008266,
     "end_time": "2025-10-21T16:53:04.992137",
     "exception": false,
     "start_time": "2025-10-21T16:53:04.983871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1girl bow brown_hair detached_sleeves frills hair_bow hair_ribbon hair_tubes hakurei_reimu highres midriff navel red_eyes ribbon skirt skirt_set solo standing touhou\n"
     ]
    }
   ],
   "source": [
    "print(top_2000_id_to_tags[\"1017000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a776d388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T16:53:04.998905Z",
     "iopub.status.busy": "2025-10-21T16:53:04.998657Z",
     "iopub.status.idle": "2025-10-21T16:53:05.002404Z",
     "shell.execute_reply": "2025-10-21T16:53:05.001567Z"
    },
    "papermill": {
     "duration": 0.008632,
     "end_time": "2025-10-21T16:53:05.003731",
     "exception": false,
     "start_time": "2025-10-21T16:53:04.995099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_tags = list(filtered_tag_counter_2000.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db55264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T16:53:05.010668Z",
     "iopub.status.busy": "2025-10-21T16:53:05.010156Z",
     "iopub.status.idle": "2025-10-21T16:53:13.123209Z",
     "shell.execute_reply": "2025-10-21T16:53:13.122393Z"
    },
    "papermill": {
     "duration": 8.11801,
     "end_time": "2025-10-21T16:53:13.124647",
     "exception": false,
     "start_time": "2025-10-21T16:53:05.006637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class DanbooruMultiLabelDataset(Dataset):\n",
    "    def __init__(self, root_dir, label_dict, unique_tags, transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: folder with all subfolders of images\n",
    "        label_dict: dict mapping 'image_id' -> list of tags\n",
    "        unique_tags: list of all unique tags (defines the multi-label space)\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.label_dict = label_dict\n",
    "        self.tag_to_idx = {tag: i for i, tag in enumerate(unique_tags)}\n",
    "        self.transform = transform\n",
    "\n",
    "        # Collect image paths\n",
    "        self.image_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for f in files:\n",
    "                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    img_id = os.path.splitext(f)[0]\n",
    "                    if img_id in label_dict:\n",
    "                        self.image_paths.append(os.path.join(subdir, f))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def encode_tags(self, tags):\n",
    "        vec = torch.zeros(len(self.tag_to_idx), dtype=torch.float32)\n",
    "        for tag in tags:\n",
    "            if tag in self.tag_to_idx:\n",
    "                vec[self.tag_to_idx[tag]] = 1.0\n",
    "        return vec\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "    \n",
    "        img_id = os.path.splitext(os.path.basename(path))[0]\n",
    "        tags_str = self.label_dict[img_id]\n",
    "    \n",
    "        # Split tags if they are stored as a space-separated string\n",
    "        if isinstance(tags_str, str):\n",
    "            tags = tags_str.split()  # split by whitespace\n",
    "        else:\n",
    "            tags = tags_str  # already a list\n",
    "    \n",
    "        label_vec = self.encode_tags(tags)\n",
    "    \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "    \n",
    "        return img, label_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cfb55ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T16:53:13.131360Z",
     "iopub.status.busy": "2025-10-21T16:53:13.131066Z",
     "iopub.status.idle": "2025-10-21T17:01:29.773928Z",
     "shell.execute_reply": "2025-10-21T17:01:29.772944Z"
    },
    "papermill": {
     "duration": 496.647837,
     "end_time": "2025-10-21T17:01:29.775491",
     "exception": false,
     "start_time": "2025-10-21T16:53:13.127654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 500])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = DanbooruMultiLabelDataset(\n",
    "    root_dir=\"/kaggle/input/tagged-anime-illustrations/danbooru-images/danbooru-images\",\n",
    "    label_dict=top_2000_id_to_tags,\n",
    "    unique_tags=unique_tags,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "for images, label_vecs in dataloader:\n",
    "    print(images.shape)      # (B, 3, 224, 224)\n",
    "    print(label_vecs.shape)  # (B, num_tags)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023f5c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:01:29.783625Z",
     "iopub.status.busy": "2025-10-21T17:01:29.783306Z",
     "iopub.status.idle": "2025-10-21T17:01:29.816009Z",
     "shell.execute_reply": "2025-10-21T17:01:29.815022Z"
    },
    "papermill": {
     "duration": 0.038377,
     "end_time": "2025-10-21T17:01:29.817282",
     "exception": false,
     "start_time": "2025-10-21T17:01:29.778905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 269626 | Val: 33703 | Test: 33704\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size  \n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # reproducible splits\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "028829b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:01:29.823900Z",
     "iopub.status.busy": "2025-10-21T17:01:29.823638Z",
     "iopub.status.idle": "2025-10-21T17:01:32.348463Z",
     "shell.execute_reply": "2025-10-21T17:01:32.347444Z"
    },
    "papermill": {
     "duration": 2.529728,
     "end_time": "2025-10-21T17:01:32.349988",
     "exception": false,
     "start_time": "2025-10-21T17:01:29.820260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 0 — Active tags: 10\n",
      "[2, 3, 13, 69, 113, 114, 118, 141, 378, 450]\n",
      "\n",
      "Sample 1 — Active tags: 13\n",
      "[0, 1, 2, 5, 52, 53, 133, 154, 190, 201, 305, 338, 371]\n",
      "\n",
      "Sample 2 — Active tags: 12\n",
      "[17, 25, 46, 50, 60, 63, 100, 128, 186, 233, 328, 384]\n",
      "\n",
      "Sample 3 — Active tags: 19\n",
      "[17, 31, 46, 58, 63, 73, 111, 118, 128, 137, 148, 170, 201, 227, 243, 311, 346, 424, 492]\n",
      "\n",
      "Sample 4 — Active tags: 18\n",
      "[2, 3, 17, 18, 23, 28, 34, 41, 62, 154, 205, 242, 284, 286, 339, 386, 476, 488]\n"
     ]
    }
   ],
   "source": [
    "# Get one batch from the dataloader\n",
    "imgs, labels = next(iter(train_loader))\n",
    "\n",
    "# Print 5 label vectors and how many active tags they have\n",
    "for i in range(5):\n",
    "    label_vec = labels[i]\n",
    "    print(f\"\\nSample {i} — Active tags: {int(label_vec.sum().item())}\")\n",
    "    print(label_vec.nonzero(as_tuple=True)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9618dbd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:01:32.357508Z",
     "iopub.status.busy": "2025-10-21T17:01:32.356968Z",
     "iopub.status.idle": "2025-10-21T17:01:33.547863Z",
     "shell.execute_reply": "2025-10-21T17:01:33.547011Z"
    },
    "papermill": {
     "duration": 1.195896,
     "end_time": "2025-10-21T17:01:33.549097",
     "exception": false,
     "start_time": "2025-10-21T17:01:32.353201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First half: 168516 samples\n",
      "Second half: 168517 samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "n = len(dataset)\n",
    "half = n // 2\n",
    "\n",
    "# ✅ Split into ordered halves first\n",
    "first_half_idx = list(range(0, half))\n",
    "second_half_idx = list(range(half, n))\n",
    "\n",
    "first_half = Subset(dataset, first_half_idx)\n",
    "second_half = Subset(dataset, second_half_idx)\n",
    "\n",
    "print(f\"First half: {len(first_half)} samples\")\n",
    "print(f\"Second half: {len(second_half)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8846adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:01:33.557208Z",
     "iopub.status.busy": "2025-10-21T17:01:33.556104Z",
     "iopub.status.idle": "2025-10-21T17:01:33.612839Z",
     "shell.execute_reply": "2025-10-21T17:01:33.611961Z"
    },
    "papermill": {
     "duration": 0.062056,
     "end_time": "2025-10-21T17:01:33.614280",
     "exception": false,
     "start_time": "2025-10-21T17:01:33.552224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_80_10_10(subset, seed):\n",
    "    n = len(subset)\n",
    "    indices = list(range(n))\n",
    "    train_idx, temp_idx = train_test_split(\n",
    "        indices, test_size=0.2, random_state=seed, shuffle=False\n",
    "    )\n",
    "    val_idx, test_idx = train_test_split(\n",
    "        temp_idx, test_size=0.5, random_state=seed, shuffle=False\n",
    "    )\n",
    "    return (\n",
    "        Subset(subset, train_idx),\n",
    "        Subset(subset, val_idx),\n",
    "        Subset(subset, test_idx),\n",
    "    )\n",
    "\n",
    "first_train, first_val, first_test = split_80_10_10(first_half, seed=RANDOM_SEED)\n",
    "second_train, second_val, second_test = split_80_10_10(second_half, seed=RANDOM_SEED + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "342f2670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:01:33.620807Z",
     "iopub.status.busy": "2025-10-21T17:01:33.620563Z",
     "iopub.status.idle": "2025-10-21T17:01:33.626095Z",
     "shell.execute_reply": "2025-10-21T17:01:33.625501Z"
    },
    "papermill": {
     "duration": 0.010044,
     "end_time": "2025-10-21T17:01:33.627237",
     "exception": false,
     "start_time": "2025-10-21T17:01:33.617193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_loader(subset, batch_size=64, shuffle=False):\n",
    "    return DataLoader(\n",
    "        subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "train_loader_1 = make_loader(first_train)\n",
    "val_loader_1   = make_loader(first_val, shuffle=False)\n",
    "test_loader_1  = make_loader(first_test, shuffle=False)\n",
    "\n",
    "train_loader_2 = make_loader(second_train)\n",
    "val_loader_2   = make_loader(second_val, shuffle=False)\n",
    "test_loader_2  = make_loader(second_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df5b3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:01:33.634100Z",
     "iopub.status.busy": "2025-10-21T17:01:33.633905Z",
     "iopub.status.idle": "2025-10-22T03:09:28.106678Z",
     "shell.execute_reply": "2025-10-22T03:09:28.105372Z"
    },
    "papermill": {
     "duration": 36475.371343,
     "end_time": "2025-10-22T03:09:29.001608",
     "exception": false,
     "start_time": "2025-10-21T17:01:33.630265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights (missing=777, unexpected=942)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 2107/2107 [57:57<00:00,  1.65s/it]\n",
      "Epoch 1/10 [Val]: 100%|██████████| 264/264 [02:18<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Train Loss: 0.1188 | Val Loss: 0.1141 | P: 0.3395 | R: 0.3299 | F1: 0.3166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 2107/2107 [58:04<00:00,  1.65s/it]\n",
      "Epoch 2/10 [Val]: 100%|██████████| 264/264 [02:17<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] | Train Loss: 0.1127 | Val Loss: 0.1104 | P: 0.3513 | R: 0.3721 | F1: 0.3427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 2107/2107 [58:11<00:00,  1.66s/it]\n",
      "Epoch 3/10 [Val]: 100%|██████████| 264/264 [02:17<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] | Train Loss: 0.1094 | Val Loss: 0.1075 | P: 0.3647 | R: 0.3949 | F1: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 2107/2107 [58:07<00:00,  1.66s/it]\n",
      "Epoch 4/10 [Val]: 100%|██████████| 264/264 [02:17<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] | Train Loss: 0.1063 | Val Loss: 0.1055 | P: 0.3708 | R: 0.4112 | F1: 0.3702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 2107/2107 [58:08<00:00,  1.66s/it]\n",
      "Epoch 5/10 [Val]: 100%|██████████| 264/264 [02:16<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] | Train Loss: 0.1035 | Val Loss: 0.1039 | P: 0.3780 | R: 0.4229 | F1: 0.3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 2107/2107 [58:10<00:00,  1.66s/it]\n",
      "Epoch 6/10 [Val]: 100%|██████████| 264/264 [02:17<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] | Train Loss: 0.1006 | Val Loss: 0.1032 | P: 0.3849 | R: 0.4274 | F1: 0.3843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 2107/2107 [58:09<00:00,  1.66s/it]\n",
      "Epoch 7/10 [Val]: 100%|██████████| 264/264 [02:17<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] | Train Loss: 0.0973 | Val Loss: 0.1030 | P: 0.3860 | R: 0.4365 | F1: 0.3883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 2107/2107 [58:10<00:00,  1.66s/it]\n",
      "Epoch 8/10 [Val]: 100%|██████████| 264/264 [02:17<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] | Train Loss: 0.0937 | Val Loss: 0.1049 | P: 0.3848 | R: 0.4289 | F1: 0.3824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 2107/2107 [58:09<00:00,  1.66s/it]\n",
      "Epoch 9/10 [Val]: 100%|██████████| 264/264 [02:17<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] | Train Loss: 0.0902 | Val Loss: 0.1065 | P: 0.3777 | R: 0.4279 | F1: 0.3780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 2107/2107 [58:07<00:00,  1.66s/it]\n",
      "Epoch 10/10 [Val]: 100%|██████████| 264/264 [02:16<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0868 | Val Loss: 0.1083 | P: 0.3766 | R: 0.4222 | F1: 0.3751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best thresholds saved to best_thresholds.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 264/264 [02:18<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Results (Tuned Thresholds)\n",
      "F1: 0.3352 | Precision: 0.2900 | Recall: 0.4729\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "# ======================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ======================\n",
    "num_classes = 500\n",
    "pretrained_weights = \"/kaggle/input/autotagger/model.pth\"\n",
    "\n",
    "model = models.resnet152(pretrained=False)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "# Load pretrained weights\n",
    "state_dict = torch.load(pretrained_weights, map_location=device)\n",
    "for k in [\"fc.weight\", \"fc.bias\"]:\n",
    "    state_dict.pop(k, None)\n",
    "missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "print(f\"Loaded pretrained weights (missing={len(missing)}, unexpected={len(unexpected)})\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# ======================\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# ======================\n",
    "def find_best_thresholds(y_true, y_pred_proba):\n",
    "    thresholds = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        p, r, t = precision_recall_curve(y_true[:, i], y_pred_proba[:, i])\n",
    "        f1 = 2 * p * r / (p + r + 1e-8)\n",
    "        if len(f1) > 0 and not np.all(np.isnan(f1)):\n",
    "            thresholds.append(t[np.nanargmax(f1)])\n",
    "        else:\n",
    "            thresholds.append(0.2)\n",
    "    return np.clip(np.array(thresholds, dtype=np.float32), 0.05, 0.95)\n",
    "\n",
    "# ======================\n",
    "num_epochs = 10\n",
    "history = {\"train_loss\": [], \"val_loss\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ---- Training ----\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for imgs, labels in tqdm(train_loader_1, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * imgs.size(0)\n",
    "    train_loss /= len(train_loader_1.dataset)\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    all_probs, all_labels = [], []\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(val_loader_1, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            probs = torch.sigmoid(outputs).cpu()\n",
    "            all_probs.append(probs)\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    val_loss /= len(val_loader_1.dataset)\n",
    "\n",
    "    # Fixed threshold (for validation tracking)\n",
    "    preds = (all_probs > 0.2).astype(int)\n",
    "    f1 = f1_score(all_labels, preds, average=\"samples\", zero_division=0)\n",
    "    precision = precision_score(all_labels, preds, average=\"samples\", zero_division=0)\n",
    "    recall = recall_score(all_labels, preds, average=\"samples\", zero_division=0)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "          f\"P: {precision:.4f} | R: {recall:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"precision\"].append(precision)\n",
    "    history[\"recall\"].append(recall)\n",
    "    history[\"f1\"].append(f1)\n",
    "\n",
    "# ======================\n",
    "# Compute best thresholds ONCE after final epoch\n",
    "best_thresholds = find_best_thresholds(all_labels, all_probs)\n",
    "np.save(\"best_thresholds.npy\", best_thresholds)\n",
    "print(\" Best thresholds saved to best_thresholds.npy\")\n",
    "\n",
    "# ======================\n",
    "# Test evaluation\n",
    "model.eval()\n",
    "all_probs, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(test_loader_1, desc=\"Testing\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        probs = torch.sigmoid(outputs).cpu()\n",
    "        all_probs.append(probs)\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "all_probs = torch.cat(all_probs).numpy()\n",
    "all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "preds = (all_probs > best_thresholds).astype(int)\n",
    "precision = precision_score(all_labels, preds, average=\"samples\", zero_division=0)\n",
    "recall = recall_score(all_labels, preds, average=\"samples\", zero_division=0)\n",
    "f1 = f1_score(all_labels, preds, average=\"samples\", zero_division=0)\n",
    "\n",
    "print(f\"\\n Test Results (Tuned Thresholds)\")\n",
    "print(f\"F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "\n",
    "# ======================\n",
    "torch.save(model.state_dict(), \"model_resnet152_finetuned_first_half.pth\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 38986,
     "sourceId": 61452,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8527771,
     "sourceId": 13435401,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37183.445393,
   "end_time": "2025-10-22T03:09:33.383474",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-21T16:49:49.938081",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
