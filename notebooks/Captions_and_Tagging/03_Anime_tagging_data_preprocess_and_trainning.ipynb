{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61452,"sourceType":"datasetVersion","datasetId":38986}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport json\nimport shutil\n\ncaption_dir = '/kaggle/input/tagged-anime-illustrations/danbooru-metadata/danbooru-metadata'\n\nid_to_tags = {}\n\nfor filename in os.listdir(caption_dir):\n    f_path = os.path.join(caption_dir, filename)\n    if os.path.isfile(f_path):\n        with open(f_path, 'r') as f:\n            for line in f:\n                data = json.loads(line.rstrip())\n                tags = [x[\"name\"] for x in data[\"tags\"]]\n                caption = \" \".join(tags)\n                id_to_tags[data[\"id\"]] = caption ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:43:32.187998Z","iopub.execute_input":"2025-10-06T08:43:32.188967Z","iopub.status.idle":"2025-10-06T08:45:33.602709Z","shell.execute_reply.started":"2025-10-06T08:43:32.188931Z","shell.execute_reply":"2025-10-06T08:45:33.601919Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from collections import Counter\n\ntag_counter = Counter()\nfor tags in id_to_tags.values():\n    for tag in tags.split(\" \"):\n        tag = tag.strip()\n        if tag:  # avoid empty strings\n            tag_counter[tag] += 1\n            \ntop_tags = [tag for tag, _ in tag_counter.most_common(2000)]\n\ntop_tags_set = set(top_tags)\n\ntop_2000_id_to_tags = {\n    img_id: \" \".join([t for t in tags.split(\" \") if t in top_tags_set])\n    for img_id, tags in id_to_tags.items()\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:45:33.603934Z","iopub.execute_input":"2025-10-06T08:45:33.604611Z","iopub.status.idle":"2025-10-06T08:46:19.416700Z","shell.execute_reply.started":"2025-10-06T08:45:33.604580Z","shell.execute_reply":"2025-10-06T08:46:19.416101Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from collections import Counter\n\nfiltered_tag_counter_2000 = Counter()\n\nfor tags in top_2000_id_to_tags.values():\n    for tag in tags.split(\" \"):\n        tag = tag.strip()\n        if tag:  \n            filtered_tag_counter_2000[tag] += 1\n\nprint(\"Total unique tags:\", len(filtered_tag_counter_2000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:46:19.417350Z","iopub.execute_input":"2025-10-06T08:46:19.417546Z","iopub.status.idle":"2025-10-06T08:46:43.364913Z","shell.execute_reply.started":"2025-10-06T08:46:19.417530Z","shell.execute_reply":"2025-10-06T08:46:43.364278Z"}},"outputs":[{"name":"stdout","text":"Total unique tags: 2000\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(top_2000_id_to_tags[\"1017000\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:46:43.366379Z","iopub.execute_input":"2025-10-06T08:46:43.366695Z","iopub.status.idle":"2025-10-06T08:46:43.370667Z","shell.execute_reply.started":"2025-10-06T08:46:43.366675Z","shell.execute_reply":"2025-10-06T08:46:43.369742Z"}},"outputs":[{"name":"stdout","text":"1girl bow brown_hair detached_sleeves frilled_skirt frills hair_bow hair_ribbon hair_tubes hakurei_reimu highres midriff navel ofuda red_eyes red_skirt ribbon sarashi skirt skirt_set solo standing touhou yin_yang\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"unique_tags = list(filtered_tag_counter_2000.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:46:43.371358Z","iopub.execute_input":"2025-10-06T08:46:43.371559Z","iopub.status.idle":"2025-10-06T08:46:43.392072Z","shell.execute_reply.started":"2025-10-06T08:46:43.371542Z","shell.execute_reply":"2025-10-06T08:46:43.391521Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass DanbooruMultiLabelDataset(Dataset):\n    def __init__(self, root_dir, label_dict, unique_tags, transform=None):\n        \"\"\"\n        root_dir: folder with all subfolders of images\n        label_dict: dict mapping 'image_id' -> list of tags\n        unique_tags: list of all unique tags (defines the multi-label space)\n        \"\"\"\n        self.root_dir = root_dir\n        self.label_dict = label_dict\n        self.tag_to_idx = {tag: i for i, tag in enumerate(unique_tags)}\n        self.transform = transform\n\n        # Collect image paths\n        self.image_paths = []\n        for subdir, _, files in os.walk(root_dir):\n            for f in files:\n                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n                    img_id = os.path.splitext(f)[0]\n                    if img_id in label_dict:\n                        self.image_paths.append(os.path.join(subdir, f))\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def encode_tags(self, tags):\n        vec = torch.zeros(len(self.tag_to_idx), dtype=torch.float32)\n        for tag in tags:\n            if tag in self.tag_to_idx:\n                vec[self.tag_to_idx[tag]] = 1.0\n        return vec\n\n    def __getitem__(self, idx):\n        path = self.image_paths[idx]\n        img = Image.open(path).convert(\"RGB\")\n\n        img_id = os.path.splitext(os.path.basename(path))[0]\n        tags = self.label_dict[img_id]\n        label_vec = self.encode_tags(tags)\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label_vec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:46:43.392784Z","iopub.execute_input":"2025-10-06T08:46:43.393045Z","iopub.status.idle":"2025-10-06T08:46:56.502571Z","shell.execute_reply.started":"2025-10-06T08:46:43.393022Z","shell.execute_reply":"2025-10-06T08:46:56.502027Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\ndataset = DanbooruMultiLabelDataset(\n    root_dir=\"/kaggle/input/tagged-anime-illustrations/danbooru-images/danbooru-images\",\n    label_dict=top_2000_id_to_tags,\n    unique_tags=unique_tags,\n    transform=transform\n)\n\ndataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)\n\nfor images, label_vecs in dataloader:\n    print(images.shape)      # (B, 3, 224, 224)\n    print(label_vecs.shape)  # (B, num_tags)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:46:56.503554Z","iopub.execute_input":"2025-10-06T08:46:56.503930Z","iopub.status.idle":"2025-10-06T08:55:32.751648Z","shell.execute_reply.started":"2025-10-06T08:46:56.503903Z","shell.execute_reply":"2025-10-06T08:55:32.750946Z"}},"outputs":[{"name":"stdout","text":"torch.Size([16, 3, 224, 224])\ntorch.Size([16, 2000])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from torch.utils.data import Subset\nfrom sklearn.model_selection import train_test_split\n\nRANDOM_SEED = 42\n\nn = len(dataset)\nhalf = n // 2\n\n# ✅ Split into ordered halves first\nfirst_half_idx = list(range(0, half))\nsecond_half_idx = list(range(half, n))\n\nfirst_half = Subset(dataset, first_half_idx)\nsecond_half = Subset(dataset, second_half_idx)\n\nprint(f\"First half: {len(first_half)} samples\")\nprint(f\"Second half: {len(second_half)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:55:32.752755Z","iopub.execute_input":"2025-10-06T08:55:32.753167Z","iopub.status.idle":"2025-10-06T08:55:33.462929Z","shell.execute_reply.started":"2025-10-06T08:55:32.753133Z","shell.execute_reply":"2025-10-06T08:55:33.462279Z"}},"outputs":[{"name":"stdout","text":"First half: 168516 samples\nSecond half: 168517 samples\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def split_80_10_10(subset, seed):\n    n = len(subset)\n    indices = list(range(n))\n    train_idx, temp_idx = train_test_split(\n        indices, test_size=0.2, random_state=seed, shuffle=True\n    )\n    val_idx, test_idx = train_test_split(\n        temp_idx, test_size=0.5, random_state=seed, shuffle=True\n    )\n    return (\n        Subset(subset, train_idx),\n        Subset(subset, val_idx),\n        Subset(subset, test_idx),\n    )\n\nfirst_train, first_val, first_test = split_80_10_10(first_half, seed=RANDOM_SEED)\nsecond_train, second_val, second_test = split_80_10_10(second_half, seed=RANDOM_SEED + 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:55:33.463656Z","iopub.execute_input":"2025-10-06T08:55:33.463992Z","iopub.status.idle":"2025-10-06T08:55:33.578289Z","shell.execute_reply.started":"2025-10-06T08:55:33.463974Z","shell.execute_reply":"2025-10-06T08:55:33.577493Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def make_loader(subset, batch_size=64, shuffle=True):\n    return DataLoader(\n        subset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        num_workers=4,\n        pin_memory=True,\n        persistent_workers=True\n    )\n\ntrain_loader_1 = make_loader(first_train)\nval_loader_1   = make_loader(first_val, shuffle=False)\ntest_loader_1  = make_loader(first_test, shuffle=False)\n\ntrain_loader_2 = make_loader(second_train)\nval_loader_2   = make_loader(second_val, shuffle=False)\ntest_loader_2  = make_loader(second_test, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:55:33.581076Z","iopub.execute_input":"2025-10-06T08:55:33.581353Z","iopub.status.idle":"2025-10-06T08:55:33.586302Z","shell.execute_reply.started":"2025-10-06T08:55:33.581336Z","shell.execute_reply":"2025-10-06T08:55:33.585689Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\n# Load the model\nmodel = torch.hub.load('RF5/danbooru-pretrained', 'resnet50')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:55:33.587152Z","iopub.execute_input":"2025-10-06T08:55:33.587367Z","iopub.status.idle":"2025-10-06T08:55:37.216228Z","shell.execute_reply.started":"2025-10-06T08:55:33.587352Z","shell.execute_reply":"2025-10-06T08:55:37.215613Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n  warnings.warn(\nDownloading: \"https://github.com/RF5/danbooru-pretrained/zipball/master\" to /root/.cache/torch/hub/master.zip\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\nDownloading: \"https://github.com/RF5/danbooru-pretrained/releases/download/v0.1/resnet50-13306192.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-13306192.pth\n100%|██████████| 110M/110M [00:01<00:00, 88.9MB/s] \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:55:37.217103Z","iopub.execute_input":"2025-10-06T08:55:37.217293Z","iopub.status.idle":"2025-10-06T08:55:37.222843Z","shell.execute_reply.started":"2025-10-06T08:55:37.217277Z","shell.execute_reply":"2025-10-06T08:55:37.222134Z"}},"outputs":[{"name":"stdout","text":"Sequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (5): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (6): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (7): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): Flatten()\n    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=4096, out_features=512, bias=True)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=6000, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch.nn as nn\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_tags = len(unique_tags)\n# Replace final layer\nmodel[1][8] = nn.Linear(in_features=512, out_features=num_tags)\nprint(f\"✅ Replaced final layer with Linear(512, {num_tags})\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:55:37.223711Z","iopub.execute_input":"2025-10-06T08:55:37.224388Z","iopub.status.idle":"2025-10-06T08:55:37.298987Z","shell.execute_reply.started":"2025-10-06T08:55:37.224362Z","shell.execute_reply":"2025-10-06T08:55:37.298428Z"}},"outputs":[{"name":"stdout","text":"✅ Replaced final layer with Linear(512, 2000)\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (5): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (6): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (7): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): Flatten()\n    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=4096, out_features=512, bias=True)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2000, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Freeze feature extractor\nfor param in model[0].parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:55:37.299613Z","iopub.execute_input":"2025-10-06T08:55:37.299845Z","iopub.status.idle":"2025-10-06T08:55:37.303872Z","shell.execute_reply.started":"2025-10-06T08:55:37.299829Z","shell.execute_reply":"2025-10-06T08:55:37.303177Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\ncriterion = nn.BCEWithLogitsLoss()  # multi-label classification\noptimizer = optim.Adam(model[1].parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:55:37.304764Z","iopub.execute_input":"2025-10-06T08:55:37.304994Z","iopub.status.idle":"2025-10-06T08:55:37.322021Z","shell.execute_reply.started":"2025-10-06T08:55:37.304976Z","shell.execute_reply":"2025-10-06T08:55:37.321450Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n\n\nnum_epochs_head = 5\nfor epoch in range(num_epochs_head):\n    model.train()\n    train_loss = 0.0\n\n    for imgs, labels in tqdm(train_loader_1, desc=f\"Epoch {epoch+1}/{num_epochs_head} [Head]\"):\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels.float())\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * imgs.size(0)\n\n    train_loss /= len(train_loader_1.dataset)\n\n    # Validation\n    model.eval()\n    all_preds, all_labels = [], []\n    val_loss = 0.0\n    with torch.no_grad():\n        for imgs, labels in val_loader_1:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels.float())\n            val_loss += loss.item() * imgs.size(0)\n\n            preds = (torch.sigmoid(outputs) > 0.5).int().cpu()\n            all_preds.append(preds)\n            all_labels.append(labels.cpu())\n\n    all_preds = torch.cat(all_preds)\n    all_labels = torch.cat(all_labels)\n    f1 = f1_score(all_labels, all_preds, average=\"micro\")\n    val_loss /= len(val_loader_1.dataset)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs_head}] - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | F1: {f1:.4f}\")\n\n\n#Unfreeze backbone for fine-tuning\n\nfor param in model[0].parameters():\n    param.requires_grad = True\n\noptimizer = optim.Adam(model.parameters(), lr=1e-5)\nnum_epochs_finetune = 3\n\nfor epoch in range(num_epochs_finetune):\n    model.train()\n    train_loss = 0.0\n\n    for imgs, labels in tqdm(train_loader_1, desc=f\"Epoch {epoch+1}/{num_epochs_finetune} [Fine-tune]\"):\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels.float())\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * imgs.size(0)\n\n    train_loss /= len(train_loader_1.dataset)\n    print(f\"Fine-tune Epoch [{epoch+1}/{num_epochs_finetune}] - Train Loss: {train_loss:.4f}\")\n\n\nmodel.eval()\nall_preds, all_labels = [], []\n\nwith torch.no_grad():\n    for imgs, labels in tqdm(test_loader_1, desc=\"Testing\"):\n        imgs, labels = imgs.to(device), labels.to(device)\n        outputs = model(imgs)\n        preds = (torch.sigmoid(outputs) > 0.5).int().cpu()\n        all_preds.append(preds)\n        all_labels.append(labels.cpu())\n\nall_preds = torch.cat(all_preds)\nall_labels = torch.cat(all_labels)\n\n\nprecision = precision_score(all_labels, all_preds, average=\"micro\")\nrecall = recall_score(all_labels, all_preds, average=\"micro\")\nf1 = f1_score(all_labels, all_preds, average=\"micro\")\nprint(f\"✅ Test F1 Score after first half: {f1:.4f}\")\nprint(f\"Precision: {precision:.4f}, Recall: {recall:.4f}\")\n\n\n\ntorch.save(model.state_dict(), \"model_half1_finetuned.pth\")\nprint(\"✅ Model saved after first half training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T08:55:37.322656Z","iopub.execute_input":"2025-10-06T08:55:37.322824Z","iopub.status.idle":"2025-10-06T10:59:01.718465Z","shell.execute_reply.started":"2025-10-06T08:55:37.322811Z","shell.execute_reply":"2025-10-06T10:59:01.717523Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/5 [Head]: 100%|██████████| 2107/2107 [09:30<00:00,  3.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/5] - Train Loss: 0.0103 | Val Loss: 0.0004 | F1: 0.7887\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5 [Head]: 100%|██████████| 2107/2107 [08:07<00:00,  4.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/5] - Train Loss: 0.0004 | Val Loss: 0.0025 | F1: 0.7358\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5 [Head]: 100%|██████████| 2107/2107 [08:08<00:00,  4.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/5] - Train Loss: 0.0004 | Val Loss: 0.0006 | F1: 0.7513\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5 [Head]: 100%|██████████| 2107/2107 [08:08<00:00,  4.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/5] - Train Loss: 0.0004 | Val Loss: 0.0004 | F1: 0.7981\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5 [Head]: 100%|██████████| 2107/2107 [08:06<00:00,  4.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/5] - Train Loss: 0.0004 | Val Loss: 0.0004 | F1: 0.7953\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3 [Fine-tune]: 100%|██████████| 2107/2107 [24:41<00:00,  1.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch [1/3] - Train Loss: 0.0003\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3 [Fine-tune]: 100%|██████████| 2107/2107 [24:42<00:00,  1.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch [2/3] - Train Loss: 0.0003\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3 [Fine-tune]: 100%|██████████| 2107/2107 [24:42<00:00,  1.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch [3/3] - Train Loss: 0.0003\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|██████████| 264/264 [01:17<00:00,  3.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ Test F1 Score after first half: 0.7568\nPrecision: 0.6940, Recall: 0.8322\n✅ Model saved after first half training\n","output_type":"stream"}],"execution_count":16}]}